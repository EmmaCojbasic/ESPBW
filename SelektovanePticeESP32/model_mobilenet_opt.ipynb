{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Emma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Emma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Emma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_128_tf_no_top.h5\n",
      "17225924/17225924 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNet(input_shape=(128, 128, 3), \n",
    "                                               include_top=False, weights='imagenet')\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=l2(0.001)),  # Regularizacija\n",
    "    layers.Dropout(0.6),  # Smanjuje overfitting\n",
    "    layers.Dense(20, activation='softmax')  # 20 je broj klasa\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss= 'categorical_crossentropy', # 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 949 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'Train',  # Putanja do foldera sa podacima za treniranje\n",
    "    target_size=(128, 128),     # Resize na 96x96\n",
    "    batch_size=16,\n",
    "    class_mode= 'categorical' ) # 'sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 119 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    'Validate',  # Putanja do foldera sa podacima za treniranje\n",
    "    target_size=(128, 128),     # Resize na 96x96\n",
    "    batch_size=16,\n",
    "    class_mode= 'categorical') #'sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\Emma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Emma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "60/60 [==============================] - 12s 166ms/step - loss: 4.6187 - accuracy: 0.0664 - val_loss: 3.3699 - val_accuracy: 0.0672 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "60/60 [==============================] - 8s 139ms/step - loss: 3.6193 - accuracy: 0.1138 - val_loss: 3.0733 - val_accuracy: 0.1681 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "60/60 [==============================] - 9s 149ms/step - loss: 3.1302 - accuracy: 0.1760 - val_loss: 2.8556 - val_accuracy: 0.2941 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "60/60 [==============================] - 9s 150ms/step - loss: 2.9128 - accuracy: 0.2234 - val_loss: 2.6824 - val_accuracy: 0.3361 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "60/60 [==============================] - 10s 164ms/step - loss: 2.6701 - accuracy: 0.2940 - val_loss: 2.5007 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "60/60 [==============================] - 10s 155ms/step - loss: 2.4636 - accuracy: 0.3751 - val_loss: 2.3375 - val_accuracy: 0.4622 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "60/60 [==============================] - 10s 157ms/step - loss: 2.3644 - accuracy: 0.3952 - val_loss: 2.2134 - val_accuracy: 0.5126 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "60/60 [==============================] - 9s 151ms/step - loss: 2.1580 - accuracy: 0.4510 - val_loss: 2.0766 - val_accuracy: 0.5546 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "60/60 [==============================] - 9s 151ms/step - loss: 2.0440 - accuracy: 0.4984 - val_loss: 1.9705 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "60/60 [==============================] - 10s 157ms/step - loss: 1.8788 - accuracy: 0.5321 - val_loss: 1.8711 - val_accuracy: 0.6050 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "60/60 [==============================] - 10s 158ms/step - loss: 1.8026 - accuracy: 0.5722 - val_loss: 1.7803 - val_accuracy: 0.6303 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "60/60 [==============================] - 10s 159ms/step - loss: 1.6888 - accuracy: 0.5985 - val_loss: 1.7184 - val_accuracy: 0.6555 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "60/60 [==============================] - 9s 154ms/step - loss: 1.6115 - accuracy: 0.6228 - val_loss: 1.6520 - val_accuracy: 0.6471 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "60/60 [==============================] - 10s 160ms/step - loss: 1.5241 - accuracy: 0.6565 - val_loss: 1.5756 - val_accuracy: 0.6891 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "60/60 [==============================] - 9s 148ms/step - loss: 1.4258 - accuracy: 0.6944 - val_loss: 1.5301 - val_accuracy: 0.6723 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "60/60 [==============================] - 10s 158ms/step - loss: 1.3712 - accuracy: 0.7018 - val_loss: 1.4785 - val_accuracy: 0.7059 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "60/60 [==============================] - 10s 157ms/step - loss: 1.2766 - accuracy: 0.7218 - val_loss: 1.4545 - val_accuracy: 0.7059 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "60/60 [==============================] - 10s 162ms/step - loss: 1.2621 - accuracy: 0.7429 - val_loss: 1.4067 - val_accuracy: 0.7059 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "60/60 [==============================] - 10s 167ms/step - loss: 1.1947 - accuracy: 0.7619 - val_loss: 1.3761 - val_accuracy: 0.7311 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "60/60 [==============================] - 9s 148ms/step - loss: 1.1373 - accuracy: 0.7914 - val_loss: 1.3534 - val_accuracy: 0.7311 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "60/60 [==============================] - 9s 150ms/step - loss: 1.0982 - accuracy: 0.7871 - val_loss: 1.3192 - val_accuracy: 0.7647 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "60/60 [==============================] - 9s 152ms/step - loss: 1.0424 - accuracy: 0.8145 - val_loss: 1.2967 - val_accuracy: 0.7479 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "60/60 [==============================] - 10s 157ms/step - loss: 1.0289 - accuracy: 0.8240 - val_loss: 1.2925 - val_accuracy: 0.7311 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "60/60 [==============================] - 10s 170ms/step - loss: 0.9619 - accuracy: 0.8462 - val_loss: 1.2603 - val_accuracy: 0.7479 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "60/60 [==============================] - 9s 146ms/step - loss: 0.9312 - accuracy: 0.8525 - val_loss: 1.2385 - val_accuracy: 0.7311 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "60/60 [==============================] - 9s 147ms/step - loss: 0.9074 - accuracy: 0.8567 - val_loss: 1.2257 - val_accuracy: 0.7395 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "60/60 [==============================] - 10s 167ms/step - loss: 0.9207 - accuracy: 0.8683 - val_loss: 1.2173 - val_accuracy: 0.7311 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "60/60 [==============================] - 10s 156ms/step - loss: 0.8640 - accuracy: 0.8757 - val_loss: 1.2041 - val_accuracy: 0.7479 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "60/60 [==============================] - 9s 143ms/step - loss: 0.8496 - accuracy: 0.8778 - val_loss: 1.1961 - val_accuracy: 0.7479 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "60/60 [==============================] - 9s 152ms/step - loss: 0.8301 - accuracy: 0.8767 - val_loss: 1.2017 - val_accuracy: 0.7395 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "60/60 [==============================] - 9s 152ms/step - loss: 0.7933 - accuracy: 0.8946 - val_loss: 1.1971 - val_accuracy: 0.7395 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "60/60 [==============================] - 10s 162ms/step - loss: 0.7783 - accuracy: 0.9073 - val_loss: 1.1712 - val_accuracy: 0.7227 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "60/60 [==============================] - 10s 162ms/step - loss: 0.7524 - accuracy: 0.9020 - val_loss: 1.1567 - val_accuracy: 0.7311 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "60/60 [==============================] - 10s 159ms/step - loss: 0.7388 - accuracy: 0.9083 - val_loss: 1.1546 - val_accuracy: 0.7479 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "60/60 [==============================] - 9s 142ms/step - loss: 0.7212 - accuracy: 0.9199 - val_loss: 1.1370 - val_accuracy: 0.7395 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "60/60 [==============================] - 10s 158ms/step - loss: 0.7208 - accuracy: 0.9199 - val_loss: 1.1309 - val_accuracy: 0.7563 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "60/60 [==============================] - 10s 167ms/step - loss: 0.7125 - accuracy: 0.9220 - val_loss: 1.1453 - val_accuracy: 0.7395 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "60/60 [==============================] - 9s 150ms/step - loss: 0.6682 - accuracy: 0.9410 - val_loss: 1.1400 - val_accuracy: 0.7647 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "60/60 [==============================] - 10s 157ms/step - loss: 0.6871 - accuracy: 0.9273 - val_loss: 1.1302 - val_accuracy: 0.7563 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "60/60 [==============================] - 10s 158ms/step - loss: 0.6470 - accuracy: 0.9347 - val_loss: 1.1107 - val_accuracy: 0.7479 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "60/60 [==============================] - 10s 158ms/step - loss: 0.6356 - accuracy: 0.9357 - val_loss: 1.0961 - val_accuracy: 0.7647 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "60/60 [==============================] - 9s 140ms/step - loss: 0.6262 - accuracy: 0.9442 - val_loss: 1.1127 - val_accuracy: 0.7395 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "60/60 [==============================] - 9s 155ms/step - loss: 0.6153 - accuracy: 0.9526 - val_loss: 1.1056 - val_accuracy: 0.7479 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "60/60 [==============================] - 10s 159ms/step - loss: 0.6269 - accuracy: 0.9505 - val_loss: 1.0944 - val_accuracy: 0.7563 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "60/60 [==============================] - 10s 158ms/step - loss: 0.6234 - accuracy: 0.9389 - val_loss: 1.0847 - val_accuracy: 0.7395 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "60/60 [==============================] - 9s 155ms/step - loss: 0.5877 - accuracy: 0.9600 - val_loss: 1.0970 - val_accuracy: 0.7311 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "60/60 [==============================] - 9s 142ms/step - loss: 0.5786 - accuracy: 0.9610 - val_loss: 1.1069 - val_accuracy: 0.7227 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "60/60 [==============================] - 10s 161ms/step - loss: 0.5847 - accuracy: 0.9673 - val_loss: 1.1020 - val_accuracy: 0.7395 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "60/60 [==============================] - 9s 142ms/step - loss: 0.5865 - accuracy: 0.9547 - val_loss: 1.0892 - val_accuracy: 0.7395 - lr: 5.0000e-05\n",
      "Epoch 50/50\n",
      "60/60 [==============================] - 9s 148ms/step - loss: 0.5574 - accuracy: 0.9663 - val_loss: 1.0869 - val_accuracy: 0.7395 - lr: 5.0000e-05\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenet_1.00_128 (Functi  (None, 4, 4, 1024)        3228864   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1024)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               262400    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                5140      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3496404 (13.34 MB)\n",
      "Trainable params: 267540 (1.02 MB)\n",
      "Non-trainable params: 3228864 (12.32 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`mobilenet_1.00_128_input` is not a valid tf.function parameter name. Sanitizing to `mobilenet_1_00_128_input`.\n",
      "WARNING:absl:`mobilenet_1.00_128_input` is not a valid tf.function parameter name. Sanitizing to `mobilenet_1_00_128_input`.\n",
      "WARNING:absl:`mobilenet_1.00_128_input` is not a valid tf.function parameter name. Sanitizing to `mobilenet_1_00_128_input`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Emma\\AppData\\Local\\Temp\\tmpakjksl26\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Emma\\AppData\\Local\\Temp\\tmpakjksl26\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('mobilenet_bird_classifier_v2.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)  # Normalizacija slika\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'Test',  # Putanja do foldera sa test podacima\n",
    "    target_size=(128, 128),  # Resize na 96x96\n",
    "    batch_size=16,\n",
    "    class_mode= 'categorical') # 'sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 150ms/step - loss: 1.1554 - accuracy: 0.7667\n",
      "Test Loss: 1.1554204225540161\n",
      "Test Accuracy: 0.7666666507720947\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n",
    "\n",
    "# Ispis rezultata\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_mobilenet_1.00_224_input:0', 'index': 0, 'shape': array([  1, 124, 124,   3]), 'shape_signature': array([ -1, 124, 124,   3]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 95, 'shape': array([ 1, 20]), 'shape_signature': array([-1, 20]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='mobilenet_bird_classifier.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open(\"mobilenet_bird_classifier_v2.tflite\", \"rb\") as f:\n",
    "    model_bytes = f.read()\n",
    "\n",
    "model_array = np.frombuffer(model_bytes, dtype=np.uint8)\n",
    "\n",
    "with open(\"model_v2.h\", \"w\") as f:\n",
    "    f.write(\"#ifndef MODEL_H\\n#define MODEL_H\\n\\n\")\n",
    "    f.write(\"const unsigned char model_tflite[] = {\")\n",
    "    \n",
    "    for i, byte in enumerate(model_array):\n",
    "        if i % 12 == 0:\n",
    "            f.write(\"\\n    \")\n",
    "        f.write(f\"0x{byte:02x}, \")\n",
    "\n",
    "    f.write(\"\\n};\\n\")\n",
    "    f.write(f\"const unsigned int model_tflite_len = {len(model_array)};\\n\\n\")\n",
    "    f.write(\"#endif // MODEL_H\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kvantizacija modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Emma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mobilenet_bird_classifier_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Emma\\AppData\\Local\\Temp\\tmpmgxzhgci\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Emma\\AppData\\Local\\Temp\\tmpmgxzhgci\\assets\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"mobilenet_bird_classifier_v2.h5\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]  # Or tf.int8 for INT8 quantization\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"mobilenet_bird_classifier_quantized.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mobilenet_bird_classifier_quantized.tflite\", \"rb\") as f:\n",
    "    model_bytes = f.read()\n",
    "\n",
    "model_array = np.frombuffer(model_bytes, dtype=np.uint8)\n",
    "\n",
    "with open(\"model_float16.h\", \"w\") as f:\n",
    "    f.write(\"#ifndef MODEL_H\\n#define MODEL_H\\n\\n\")\n",
    "    f.write(\"const unsigned char model_tflite[] = {\")\n",
    "    \n",
    "    for i, byte in enumerate(model_array):\n",
    "        if i % 12 == 0:\n",
    "            f.write(\"\\n    \")\n",
    "        f.write(f\"0x{byte:02x}, \")\n",
    "\n",
    "    f.write(\"\\n};\\n\")\n",
    "    f.write(f\"const unsigned int model_tflite_len = {len(model_array)};\\n\\n\")\n",
    "    f.write(\"#endif // MODEL_H\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For full integer quantization, a `representative_dataset` must be specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m converter\u001b[38;5;241m.\u001b[39moptimizations \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mOptimize\u001b[38;5;241m.\u001b[39mDEFAULT]\n\u001b[0;32m      5\u001b[0m converter\u001b[38;5;241m.\u001b[39mtarget_spec\u001b[38;5;241m.\u001b[39msupported_types \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mint8]  \u001b[38;5;66;03m# Or tf.int8 for INT8 quantization\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m tflite_model \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmobilenet_bird_classifier_quantized_int8.tflite\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     10\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(tflite_model)\n",
      "File \u001b[1;32mc:\\Users\\Emma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1139\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(convert_func)\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1138\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1139\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_and_export_metrics(convert_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Emma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1091\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[1;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wraps around convert function to export metrics.\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \n\u001b[0;32m   1082\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;124;03m  The decorator to wrap the convert function.\u001b[39;00m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_increase_conversion_attempt_metric()\n\u001b[1;32m-> 1091\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_conversion_params_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1092\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n\u001b[0;32m   1093\u001b[0m result \u001b[38;5;241m=\u001b[39m convert_func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Emma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:921\u001b[0m, in \u001b[0;36mTFLiteConverterBase._save_conversion_params_metric\u001b[1;34m(self, graph_def, inference_type, inference_input_type)\u001b[0m\n\u001b[0;32m    918\u001b[0m converter_kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_base_converter_args())\n\u001b[0;32m    920\u001b[0m \u001b[38;5;66;03m# Optimization parameters.\u001b[39;00m\n\u001b[1;32m--> 921\u001b[0m quant_mode \u001b[38;5;241m=\u001b[39m \u001b[43mQuantizationMode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentative_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_experimental_disable_per_channel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental_new_dynamic_range_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_experimental_low_bit_qat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_experimental_full_integer_quantization_bias_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_experimental_variable_quantization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m converter_kwargs\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_version\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mtensorflowVersion,\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mapiVersion,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivations_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: quant_mode\u001b[38;5;241m.\u001b[39mactivations_type(),\n\u001b[0;32m    952\u001b[0m })\n\u001b[0;32m    953\u001b[0m converter_kwargs\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m    954\u001b[0m     quant_mode\u001b[38;5;241m.\u001b[39mconverter_flags(inference_type, inference_input_type)\n\u001b[0;32m    955\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Emma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:267\u001b[0m, in \u001b[0;36mQuantizationMode.__init__\u001b[1;34m(self, optimizations, target_spec, representative_dataset, graph_def, disable_per_channel, experimental_new_dynamic_range_quantizer, experimental_low_bit_qat, full_integer_quantization_bias_type, experimental_mlir_variable_quantization)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_def \u001b[38;5;241m=\u001b[39m graph_def\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_int8_target_required():\n\u001b[1;32m--> 267\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_int8_required\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_mlir_variable_quantization \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    270\u001b[0m     experimental_mlir_variable_quantization\n\u001b[0;32m    271\u001b[0m )\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_float16_target_required():\n",
      "File \u001b[1;32mc:\\Users\\Emma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:497\u001b[0m, in \u001b[0;36mQuantizationMode._validate_int8_required\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;66;03m# Check if representative_dataset is specified.\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_representative_dataset\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_quantization_aware_training()\n\u001b[0;32m    496\u001b[0m ):\n\u001b[1;32m--> 497\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    498\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor full integer quantization, a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`representative_dataset` must be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    500\u001b[0m   )\n\u001b[0;32m    502\u001b[0m \u001b[38;5;66;03m# Update represenative dataset to the expected format.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_representative_dataset:\n",
      "\u001b[1;31mValueError\u001b[0m: For full integer quantization, a `representative_dataset` must be specified."
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"mobilenet_bird_classifier_v2.h5\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.int8]  # Or tf.int8 for INT8 quantization\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"mobilenet_bird_classifier_quantized_int8.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mobilenet_bird_classifier_quantized_int8.tflite\", \"rb\") as f:\n",
    "    model_bytes = f.read()\n",
    "\n",
    "model_array = np.frombuffer(model_bytes, dtype=np.uint8)\n",
    "\n",
    "with open(\"model_int8.h\", \"w\") as f:\n",
    "    f.write(\"#ifndef MODEL_H\\n#define MODEL_H\\n\\n\")\n",
    "    f.write(\"const unsigned char model_tflite[] = {\")\n",
    "    \n",
    "    for i, byte in enumerate(model_array):\n",
    "        if i % 12 == 0:\n",
    "            f.write(\"\\n    \")\n",
    "        f.write(f\"0x{byte:02x}, \")\n",
    "\n",
    "    f.write(\"\\n};\\n\")\n",
    "    f.write(f\"const unsigned int model_tflite_len = {len(model_array)};\\n\\n\")\n",
    "    f.write(\"#endif // MODEL_H\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
